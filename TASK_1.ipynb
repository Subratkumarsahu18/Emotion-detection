{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd0153ab-b495-4fba-a783-6bd4c4df9724",
   "metadata": {},
   "source": [
    "# ðŸ§  Emotion Detection from Text using Machine Learning\n",
    "\n",
    "### ðŸ“Œ Project Overview\n",
    "This project detects human emotions (like joy, sadness, anger, fear, love, and surprise) based on textual input using a supervised machine learning approach.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“‚ Dataset Source\n",
    "- **Name:** DAIR-AI Emotion Dataset  \n",
    "- **Link:** [https://huggingface.co/datasets/dair-ai/emotion](https://huggingface.co/datasets/dair-ai/emotion)  \n",
    "- **Size:** ~16,000 real-world English sentences with 6 labeled emotions.\n",
    "\n",
    "---\n",
    "\n",
    "### âš™ï¸ What This Project Does\n",
    "- Cleans raw text using `neattext`\n",
    "- Converts text into features using **TF-IDF**\n",
    "- Trains a **Multinomial Naive Bayes classifier**\n",
    "- Evaluates with precision, recall, and F1-score\n",
    "- Predicts emotion for any custom user input\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Final Accuracy Achieved\n",
    "- **Accuracy:** ~78%\n",
    "- **Strong performance** on emotions like **joy** and **sadness**\n",
    "- Scope to improve **love** and **surprise** with more data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85945496-2dbb-406d-8fee-c4bc447fcc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (4.66.5)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.31.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Downloading huggingface_hub-0.31.2-py3-none-any.whl (484 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Installing collected packages: xxhash, multiprocess, huggingface-hub, datasets\n",
      "Successfully installed datasets-3.6.0 huggingface-hub-0.31.2 multiprocess-0.70.16 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "09a7431d-896f-499b-be42-0400fa18b7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  emotion\n",
       "0                            i didnt feel humiliated  sadness\n",
       "1  i can go from feeling so hopeless to so damned...  sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong    anger\n",
       "3  i am ever feeling nostalgic about the fireplac...     love\n",
       "4                               i am feeling grouchy    anger"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the 'train' split of the dataset\n",
    "dataset = load_dataset(\"dair-ai/emotion\", split='train')\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "df = dataset.to_pandas()\n",
    "\n",
    "# Map integer labels to emotion names\n",
    "label_map = {\n",
    "    0: \"sadness\",\n",
    "    1: \"joy\",\n",
    "    2: \"love\",\n",
    "    3: \"anger\",\n",
    "    4: \"fear\",\n",
    "    5: \"surprise\"\n",
    "}\n",
    "df['emotion'] = df['label'].map(label_map)\n",
    "\n",
    "# Keep only required columns\n",
    "df = df[['text', 'emotion']]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b39f615-f5e2-4d2f-ae07-50b531ec71f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neattext in c:\\users\\user\\anaconda3\\lib\\site-packages (0.1.3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>feeling hopeless damned hopeful cares awake</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>im grabbing minute post feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>feeling nostalgic fireplace know property</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                            i didnt feel humiliated   \n",
       "1  i can go from feeling so hopeless to so damned...   \n",
       "2   im grabbing a minute to post i feel greedy wrong   \n",
       "3  i am ever feeling nostalgic about the fireplac...   \n",
       "4                               i am feeling grouchy   \n",
       "\n",
       "                                    clean_text  emotion  \n",
       "0                        didnt feel humiliated  sadness  \n",
       "1  feeling hopeless damned hopeful cares awake  sadness  \n",
       "2    im grabbing minute post feel greedy wrong    anger  \n",
       "3    feeling nostalgic fireplace know property     love  \n",
       "4                              feeling grouchy    anger  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install neattext if not installed\n",
    "!pip install neattext\n",
    "\n",
    "import neattext.functions as nfx\n",
    "\n",
    "# Remove stopwords, punctuations, etc.\n",
    "df['clean_text'] = df['text'].apply(nfx.remove_userhandles)\n",
    "df['clean_text'] = df['clean_text'].apply(nfx.remove_hashtags)\n",
    "df['clean_text'] = df['clean_text'].apply(nfx.remove_punctuations)\n",
    "df['clean_text'] = df['clean_text'].apply(nfx.remove_stopwords)\n",
    "\n",
    "df[['text', 'clean_text', 'emotion']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "255d0d2b-0710-43d7-96f0-de6e7d575f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Vectorize the clean text\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(df['clean_text'])\n",
    "\n",
    "# Labels\n",
    "y = df['emotion']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b0ddd185-0d94-4ce4-aa69-1b69924f2fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7803125\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.88      0.67      0.76       427\n",
      "        fear       0.82      0.63      0.71       397\n",
      "         joy       0.75      0.94      0.83      1021\n",
      "        love       0.88      0.35      0.51       296\n",
      "     sadness       0.77      0.94      0.85       946\n",
      "    surprise       0.77      0.09      0.16       113\n",
      "\n",
      "    accuracy                           0.78      3200\n",
      "   macro avg       0.81      0.60      0.64      3200\n",
      "weighted avg       0.79      0.78      0.76      3200\n",
      "\n",
      "\n",
      "What the Report Tells Us:\n",
      "Accuracy: 78.03% on 3200 test samples\n",
      "Joy & Sadness: High recall (model is strong)\n",
      "Love & Surprise: Low recall (needs more samples or refinement)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Naive Bayes model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print metrics\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "\n",
    "# Summary of insights\n",
    "print(\"\\nWhat the Report Tells Us:\")\n",
    "print(f\"Accuracy: {round(acc * 100, 2)}% on {len(y_test)} test samples\")\n",
    "print(\"Joy & Sadness: High recall (model is strong)\")\n",
    "print(\"Love & Surprise: Low recall (needs more samples or refinement)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1897f74c-9f4f-4061-bbeb-f0900b0f27d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and vectorizer saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, \"emotion_classifier_model.pkl\")\n",
    "joblib.dump(cv, \"vectorizer.pkl\")\n",
    "\n",
    "print(\"Model and vectorizer saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "37c81694-afa0-48dd-8799-c868711b116f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your text:  I'm really anxious about tomorrow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Emotion: fear\n"
     ]
    }
   ],
   "source": [
    "# Load model and vectorizer\n",
    "model = joblib.load(\"emotion_classifier_model.pkl\")\n",
    "vectorizer = joblib.load(\"vectorizer.pkl\")\n",
    "\n",
    "# Predict function\n",
    "def predict_emotion(text):\n",
    "    clean = nfx.remove_stopwords(nfx.remove_punctuations(text))\n",
    "    vect_text = vectorizer.transform([clean])\n",
    "    return model.predict(vect_text)[0]\n",
    "\n",
    "# Take user input\n",
    "user_input = input(\"Enter your text: \")\n",
    "predicted_emotion = predict_emotion(user_input)\n",
    "\n",
    "print(f\"Predicted Emotion: {predicted_emotion}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
